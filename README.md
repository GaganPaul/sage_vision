# Sage Vision
SageVision is a local-first, vision-centric video summarisation framework that generates meaningful summaries without relying on audio transcripts.

Unlike traditional video summarizers that depend on speech-to-text pipelines, SageVision treats visual understanding as the primary signal, making it suitable for silent videos, privacy-sensitive environments, and offline use.

**Key Features:**

```python
ğŸ§  Vision-first summarization:  no transcript required
ğŸ’» Runs fully locally (CPU or GPU)
ğŸ”’ Privacy-preserving:  no cloud or external APIs needed
ğŸï¸ Scene-aware & keyframe:  based processing
ğŸ“‰ Minimal LLM usage through hierarchical summarization
ğŸ§© Modular & extensible open:   source architecture
```

## **ğŸ” Why SageVision?**
```python
Most existing video summarization tools follow this pipeline:

Video â†’ Audio â†’ Transcript â†’ LLM â†’ Summary
```

**SageVision instead follows:**

**Video â†’ Visual Understanding â†’ Semantic Compression â†’ Summary**

**This makes SageVision especially useful for:**

```python
Silent or music-only videos
Educational videos with slides
Surveillance and CCTV footage
Accessibility use cases
Low-bandwidth or offline environments
```

## **ğŸ—ï¸ System Overview:**

**High-level Pipeline:**

```python
Video
  â†“
Scene Detection
  â†“
Keyframe Extraction
  â†“
Vision Captioning
  â†“
Scene level Summaries
  â†“
Final Video Summary
```


Core Design Principles
Compress before reasoning
Scenes over frames
LLMs as aggregators, not perception engines
Local-first by default


## **ğŸ§© Architecture:**

```python
sagevision/
â”œâ”€â”€ video_parser/        ## Video decoding (FFmpeg / OpenCV)
â”œâ”€â”€ scene_detector/      ## Shot & scene boundary detection
â”œâ”€â”€ keyframe_selector/   ## Adaptive keyframe sampling
â”œâ”€â”€ vision_captioner/    ## Image-to-text (Florence-2, BLIP, etc.)
â”œâ”€â”€ summarizer/          ## Lightweight text summarization
â”œâ”€â”€ pipeline/            ## End-to-end orchestration
â”œâ”€â”€ cli/                 ## Command-line interface
â””â”€â”€ utils/               ## Shared utilities
```

Each module is replaceable and configurable, enabling experimentation with different models and strategies.

## **ğŸ–¥ï¸ Local Execution Modes:**


Mode:	Description

CPU-only:	Fully offline, slower but accessible

GPU-accelerated:	Faster vision captioning & summarization

Research mode:	Plug in custom models & heuristics


SageVision is designed to scale down gracefully to low-resource machines.

## **ğŸš€ Getting Started (Planned):**

```python
git clone https://github.com/GaganPaul/sage_vision
cd sagevision
pip install -r requirements.txt

```
## **ğŸ¯ Project Goals:**


Enable transcript-less video summarization

Reduce dependency on large multimodal LLMs

Support offline & edge deployments

Provide a clean, research-friendly codebase

Serve as a foundation for further work in visual understanding


## **ğŸš« Non-Goals:**


Real-time live video summarization

Emotion or intent-level reasoning

Replacing transcript-based summarizers

Cloud-first or API-dependent workflows


## **ğŸ“š Use Cases:**

Education & self-learning

Accessibility tools

Video archiving & indexing

Research & benchmarking

NGOs and low-connectivity regions

Privacy-sensitive video analysis

## **ğŸ§  Research Alignment:**

**SageVision can be positioned as:**

A local-first, vision-centric video summarization system that minimizes LLM usage through adaptive scene-based compression.

## **The project is suitable for:**

Applied research

System papers

Open-source contributions

Academic demos and benchmarks

## **ğŸ¤ Contributing:**

Contributions are welcome!

## **You can help by:**

Improving keyframe selection strategies

Adding new vision captioning models

Optimizing performance for CPU-only setups

Improving documentation and examples

Contribution guidelines will be added soon.

## **ğŸ“„ License:**

This project will be released under a permissive open-source license (TBD).

## **ğŸŒ± Project Status:**

**ğŸŸ¡ Active development**

Core architecture and pipeline design are complete.
Implementation is ongoing.

